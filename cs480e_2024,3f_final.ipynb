{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbron64/CS550_Lab4/blob/main/cs480e_2024%2C3f_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS480E/580E: Final Exam\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NVU1oJYOZ4RI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Michael Bronikowski\n",
        "\n",
        "B-number: B00808654\n",
        "\n",
        "E-mail: mbronik1@binghamton.edu"
      ],
      "metadata": {
        "id": "XMTeg9PBff_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Instructions\n",
        "### Due December 13th, 11:59 PM.\n",
        "\n",
        "In the final exam, you will use autoencoders to do dimensionality reduction on the MNIST images. You will then use the reduced dimensional representations to perform similarity search on test images. At the end of notebook, you will be able to retrieve k-most similar images on the training set.  \n",
        "\n",
        "\n",
        "Functions and cells that need to be implemented are marked with a bold **implement** keyword or clearly marked in the experiments section.\n",
        "\n",
        "Make sure to **run** the cells marked for running to make sure all the data and functions are available.\n",
        "\n",
        "The GitHub link is here: https://classroom.github.com/a/PQyT1LP2. You must have 15 commits for this.\n",
        "\n",
        "**AI is not allowed for this final.**\n",
        "This is in an intro course,\n",
        "so we want you to learn the fundamentals first.\n",
        "Maybe in 10 years that will change,\n",
        "but we are not there yet."
      ],
      "metadata": {
        "id": "wl3YVu4ZFABa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to import libraries."
      ],
      "metadata": {
        "id": "rR3ppk_X43X0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Xtjmf2iZ0g3"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision.datasets as dset\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# for plotting\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['font.size'] = 16\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "You will be working on the MNIST dataset, which is 60,000 training and 10,000 test images. Each picture contains a centered image of white digit on black background (0 through 9).\n",
        "\n",
        "To simplify our code here, use the PyTorch MNIST wrapper, which downloads and loads the MNIST dataset. See the [documentation](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py) for more information about the interface. The default parameters will take 5,000 of the training examples and place them into a validation dataset. The data will be saved into a folder called `MNIST_data`.\n",
        "\n",
        "**Run** the following cell to mount your drive on colab."
      ],
      "metadata": {
        "id": "xfi1dtm9F-WG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "o7LzaKFO3YEB",
        "outputId": "088b76f6-dedf-4938-adef-d17d3a1a3b29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cells to retrieve the MNIST training, validation, and test sets"
      ],
      "metadata": {
        "id": "JMhyPVyA4irk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = dset.MNIST('./MNIST_data', train=True, download=True,\n",
        "                           transform=T.ToTensor())\n",
        "\n",
        "mnist_test = dset.MNIST('./MNIST_data', train=False, download=True,\n",
        "                        transform=T.ToTensor())\n",
        "\n",
        "mnist_train, mnist_validation = random_split(mnist_train, [.8, .2])"
      ],
      "metadata": {
        "id": "AZUtLcYC3aU3",
        "outputId": "a1e12fd9-a44d-437c-a896-42b2b16d09e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 487kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.47MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.23MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** this cell to print the number of cells on the traning, validation, and test datasets."
      ],
      "metadata": {
        "id": "TvKznGC14v_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(mnist_train), len(mnist_validation), len(mnist_test))"
      ],
      "metadata": {
        "id": "5mtDzRQ3aKtL",
        "outputId": "53214e6e-fd29-4304-f28b-b49bcee5dbd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48000 12000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** this cell to define the helper function to generate grids of images."
      ],
      "metadata": {
        "id": "BkemVCHR4u4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(images):\n",
        "    images = torch.reshape(\n",
        "        images, [images.shape[0], -1]\n",
        "    )  # images reshape to (batch_size, D)\n",
        "    sqrtn = int(math.ceil(math.sqrt(images.shape[0])))\n",
        "    sqrtimg = int(math.ceil(math.sqrt(images.shape[1])))\n",
        "\n",
        "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
        "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis(\"off\")\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect(\"equal\")\n",
        "        plt.imshow(img.reshape([sqrtimg, sqrtimg]))\n",
        "    return"
      ],
      "metadata": {
        "id": "vRV_XaaN3fzC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following cell to define a `batch_size`, `loader_train`, and `loader_validation`.\n",
        "\n",
        "`batch_size` should be an integer value that defines the number of samples per mini-batch that will be used for the training dataloader.\n",
        "\n",
        "`loader_train` should be a PyTorch DataLoader on the `mnist_train` dataset with `batch_size = batch_size`, `shuffle` enabled and drop the last mini-batch.\n",
        "\n",
        "`loader_validation` should be a PyTorch DataLoader on the `mnist_validation` dataset. Set the `batch_size` as high as possible for this."
      ],
      "metadata": {
        "id": "cZ7eSC02Hnkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== BEGIN SOLUTION CODE ====\n",
        "batch_size = 1000\n",
        "\n",
        "loader_train = DataLoader(\n",
        "    mnist_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "loader_validation = DataLoader(\n",
        "    mnist_validation,\n",
        "    batch_size=len(mnist_validation),\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "# ==== END SOLUTION CODE ===="
      ],
      "metadata": {
        "id": "3yWKhZSIHnzb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to show an example of a grid of MNIST images."
      ],
      "metadata": {
        "id": "_Ck6ToupcrH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = next(iter(loader_train))[0].view(batch_size, 784)\n",
        "show_images(imgs[:36])"
      ],
      "metadata": {
        "id": "TeOLsn2D37Ej",
        "outputId": "60e4352f-a3ba-43a8-9a3b-824d52951469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 36 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Part 1) Autoencoder - 100 pts\n",
        "\n",
        "In the next cell, **implement** the definition of the `AutoEncoder` class, that implements an autoencoder using convolutions, transpose convolutions, fully connected and non-linear activation layers.\n",
        "\n",
        "\n",
        "\n",
        "You are free to choose any architecture you would like.\n",
        "**But your network must use at least 1 convolution layer**\n",
        "\n",
        "\n",
        "Complete the following methods:\n",
        "\n",
        "- `__init__(height, width, latent_dim)`: Initializes the desired layer and architecture.\n",
        "  - The inputs to the class constructor are:\n",
        "    - `height`: The height of the input images\n",
        "    - `width`: The width of the input images\n",
        "    - `latent_dim`: The size of the latent vector\n",
        "- `encode(x)`: Encodes a batch of images `x` to a batch of latent vectors, `h`\n",
        "- `decode(h)`: Decodes a batch of latent vectors `h` to a batch images, `x_reconstructed`\n",
        "- `forward(x)`: Uses `encode` and `decode` method to compress and reconstruct a batch of images, `x`."
      ],
      "metadata": {
        "id": "zwZIkT7VHunv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, height, width, latent_dim):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        conv_height = height // 4  # After 2 stride-2 convolutions: 28->14->7\n",
        "        conv_width = width // 4    # After 2 stride-2 convolutions: 28->14->7\n",
        "\n",
        "        # Calculate flattened dimension after convolutions\n",
        "        flattened_size = 32 * conv_height * conv_width\n",
        "\n",
        "        # Encoder network\n",
        "        self.encoder = nn.Sequential(\n",
        "            # First conv block: 1->16 channels\n",
        "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Second conv block: 16->32 channels\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Flatten layer\n",
        "            nn.Flatten(),\n",
        "\n",
        "            # Fully connected to latent space\n",
        "            nn.Linear(flattened_size, latent_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder network\n",
        "        self.decoder = nn.Sequential(\n",
        "            # Fully connected from latent space\n",
        "            nn.Linear(latent_dim, flattened_size),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Reshape back to 3D tensor\n",
        "            nn.Unflatten(1, (32, conv_height, conv_width)),\n",
        "\n",
        "            # First transpose conv: 32->16 channels\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Second transpose conv: 16->1 channels\n",
        "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()  # Sigmoid to get values between 0 and 1\n",
        "        )\n",
        "\n",
        "        # ==== END SOLUTION CODE ====\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        h = None\n",
        "        # ==== BEGIN SOLUTION CODE ====\n",
        "        h = self.encoder(x)\n",
        "        # ==== END SOLUTION CODE ====\n",
        "        return h\n",
        "\n",
        "    def decode(self, h):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        x_reconstructed = None\n",
        "        # ==== BEGIN SOLUTION CODE ====\n",
        "        x_reconstructed = self.decoder(h)\n",
        "        # ==== END SOLUTION CODE ====\n",
        "        return x_reconstructed\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        x_reconstructed = None\n",
        "        # ==== BEGIN SOLUTION CODE ====\n",
        "        x_reconstructed = self.decode(self.encode(x))\n",
        "        # ==== END SOLUTION CODE ====\n",
        "        return x_reconstructed"
      ],
      "metadata": {
        "id": "W9z_1RRt3_sk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoder Training (60 pts)\n",
        "\n",
        "In the following cell, define an autoencoder (AE) and train on the training set.\n",
        "\n",
        "The AE training algorithm is as follows:\n",
        "\n",
        "1. Instantiate an `AutoEncoder`. Set it to the `model` variable.\n",
        "2. Define a dataloader in order to do mini-batch training. Batch size is up to you. (You should have done this in above cells.)\n",
        "3. Define an optimizer for your AE\n",
        "4. For each batch of data in `loader_train`:\n",
        "    - Pass the input through the AE to get the reconstructed input\n",
        "    - Calculate the loss using the [`nn.functional.binary_cross_entropy`](https://pytorch.org/docs/stable/generated/torch.nn.functional.binary_cross_entropy.html)\n",
        "    - Zero the gradients, propagate the loss backwards, and update the  weights using the optimizer\n",
        "\n",
        "5. Repeat 4\n",
        "6. After N iterations (or every epoch), compute the validation loss over the validation set (using the `loader_validation`).\n"
      ],
      "metadata": {
        "id": "UGxY6-fS5-Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = None # Instantiate your model to this variable\n",
        "\n",
        "# ==== BEGIN SOLUTION CODE ====\n",
        "# Hyperparameters\n",
        "latent_dim = 32\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Initialize model\n",
        "model = AutoEncoder(height=28, width=28, latent_dim=latent_dim)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    # Training phase\n",
        "    for batch_idx, (data, _) in enumerate(loader_train):\n",
        "        # Forward pass\n",
        "        reconstructed = model(data)\n",
        "        loss = nn.functional.binary_cross_entropy(reconstructed, data)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss\n",
        "        epoch_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    # Average training loss for epoch\n",
        "    avg_train_loss = epoch_loss / num_batches\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    num_val_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_data, _ in loader_validation:\n",
        "            # Forward pass\n",
        "            val_reconstructed = model(val_data)\n",
        "            val_loss += nn.functional.binary_cross_entropy(val_reconstructed, val_data).item()\n",
        "            num_val_batches += 1\n",
        "\n",
        "    # Calculate average validation loss\n",
        "    avg_val_loss = val_loss / num_val_batches\n",
        "\n",
        "    # Progress\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "    print(f'Training Loss: {avg_train_loss:.4f}')\n",
        "    print(f'Validation Loss: {avg_val_loss:.4f}')\n",
        "    print('-' * 50)\n",
        "\n",
        "# ==== END SOLUTION CODE ====\n",
        "assert model is not None"
      ],
      "metadata": {
        "id": "aKoxFGZb59FS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3289dbd-4b83-4fc3-d80f-dca08b782fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]\n",
            "Training Loss: 0.4207\n",
            "Validation Loss: 0.2731\n",
            "--------------------------------------------------\n",
            "Epoch [2/10]\n",
            "Training Loss: 0.2661\n",
            "Validation Loss: 0.2610\n",
            "--------------------------------------------------\n",
            "Epoch [3/10]\n",
            "Training Loss: 0.2555\n",
            "Validation Loss: 0.2460\n",
            "--------------------------------------------------\n",
            "Epoch [4/10]\n",
            "Training Loss: 0.2257\n",
            "Validation Loss: 0.1956\n",
            "--------------------------------------------------\n",
            "Epoch [5/10]\n",
            "Training Loss: 0.1658\n",
            "Validation Loss: 0.1406\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following cell to generate 36 random reconstructions from your previously trained AE model and visualize the outputs."
      ],
      "metadata": {
        "id": "4cxGWAFrxumZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== BEGIN SOLUTION CODE ====\n",
        "\n",
        "# A batch of images from the training set\n",
        "data_iter = iter(loader_train)  # Assuming loader_train is defined\n",
        "images, _ = next(data_iter)\n",
        "\n",
        "# 36 random images from the batch\n",
        "num_reconstructions = 36\n",
        "random_indices = random.sample(range(len(images)), num_reconstructions)\n",
        "random_images = images[random_indices]\n",
        "\n",
        "# Reconstructing images\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    reconstructions = model(random_images)\n",
        "\n",
        "# Plot\n",
        "show_images(reconstructions)\n",
        "\n",
        "# ==== END SOLUTION CODE ===="
      ],
      "metadata": {
        "id": "pXyDl3Jg6kRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masked Autoencoder Training (40 pts)\n",
        "\n",
        "Masked autoencoders (MAE) are autoencoder models trained with corrupted images via masking out random pixel values to 0.\n",
        "\n",
        "In the following cell, define a masked autoencoder (MAE) and train on the training set.\n",
        "\n",
        "The MAE training algorithm is as follows:\n",
        "\n",
        "1. Instantiate an `AutoEncoder`. Set it to the `mae_model` variable\n",
        "2. Define an optimizer for your MAE\n",
        "3. For each `batch` of data in `loader_train`:\n",
        "    - Get the (image, label) tuple. You can discard the label.\n",
        "    - Get the `masked_image` by using the `random_mask` function given below.\n",
        "    - Pass the masked input, `masked_image` through the MAE to get the reconstructed input\n",
        "    - Calculate the loss using the [`nn.functional.binary_cross_entropy`](https://pytorch.org/docs/stable/generated/torch.nn.functional.binary_cross_entropy.html). The loss should be calculated between the reconstructed image (the output of the model) and the original unmasked image.\n",
        "    - Zero the gradients, propagate the loss backwards, and update the  weights using the optimizer\n",
        "\n",
        "4. Repeat 3\n",
        "5. After N iterations (or every epoch), compute the validation loss over the validation set (using the `loader_validation`).\n",
        "\n",
        "**Note** This is a more difficult learning task compared to regular autoencoder training, so you will have update hyperparameters to get good results"
      ],
      "metadata": {
        "id": "FfNXjRIOMSQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Run* the following cell to show an example of a grid of MNIST images that have been masked."
      ],
      "metadata": {
        "id": "wCjgBqMDcsfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_mask(image_batch, mask_percent=0.3):\n",
        "    '''Takes a batch of images and masks random pixels'''\n",
        "    assert len(image_batch.shape) == 4, \"Expected a batch of images.\"\n",
        "    copy_batch = image_batch.clone()\n",
        "    device = image_batch.device\n",
        "    orig_shape = image_batch.shape\n",
        "    num_elem = torch.numel(image_batch)\n",
        "\n",
        "    non_zero_pixels = torch.argwhere(copy_batch.view(-1) > 0)\n",
        "    num_non_zero = non_zero_pixels.shape[0]\n",
        "    mask_num = int(num_non_zero * mask_percent)\n",
        "\n",
        "    permute = torch.randperm(num_non_zero)\n",
        "    mask_pixels = non_zero_pixels[permute[:mask_num]]\n",
        "\n",
        "    copy_batch = copy_batch.view(-1)\n",
        "    copy_batch[mask_pixels] = 0\n",
        "    copy_batch = copy_batch.view(orig_shape)\n",
        "    return copy_batch\n",
        "\n",
        "imgs = next(iter(loader_train))[0]\n",
        "masked_imgs = random_mask(imgs).view(batch_size, 784)\n",
        "show_images(masked_imgs[:36])"
      ],
      "metadata": {
        "id": "Xeu2UJIcNoxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae_model = None # Instantiate your model to this variable\n",
        "\n",
        "# ==== BEGIN SOLUTION CODE ====\n",
        "\n",
        "\n",
        "# ==== END SOLUTION CODE ====\n",
        "assert mae_model is not None"
      ],
      "metadata": {
        "id": "6Xx5nYOPaodS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following cell to generate 36 random reconstructions from your previously trained MAE model and visualize the outputs."
      ],
      "metadata": {
        "id": "TS0R4kOkam-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== BEGIN SOLUTION CODE ====\n",
        "\n",
        "# ==== END SOLUTION CODE ===="
      ],
      "metadata": {
        "id": "VbuUx4t6PUJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Part 2, 40 pts Extra Credit) Similarity Search\n",
        "\n",
        "Now using your trained model, you will generate latent vectors of the training images. This will encode the images into a vector.\n",
        "\n",
        "You will also use your trained models to encode a test image into a vector, compute a similarity measure ($L_2$ or Cosine-similarity) with the training latent vectors."
      ],
      "metadata": {
        "id": "-o27ZbMwHZl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following cell to complete the `generate_latent_vectors` function.\n",
        "\n",
        "The arguments are:\n",
        "\n",
        "- `model`: The model used to generate the latent encodings\n",
        "- `dataset`: The dataset to the generate the latent encodings\n",
        "\n",
        "Returns:\n",
        "- PyTorch tensor of latent vectors computed from the dataset images using the model. It should be a 2D tensor with `len(dataset)` rows and `latent_dim` columns.\n",
        "\n",
        "Iterate over each image in the `dataset` and `encode` the images using the `model`. Make sure to turn off backprop and gradient calculations using `with torch.no_grad()` and set the model to evaluation mode using `model.eval()`.\n",
        "\n",
        "You may find the `torch.vstack` function useful.\n",
        "\n",
        "Also, your code may be written to expect a batch dimension such that images are\n",
        "(num_samples, 1, 28, 28), so you may have to use `.unsqueeze(0)` to convert a single image to a batch of images with a single image.\n"
      ],
      "metadata": {
        "id": "iu7EbzxPxx9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_latent_vectors(model, dataset):\n",
        "    '''\n",
        "    Iterates over the dataset and uses the model to generates latent vectors.\n",
        "    Returns a Torch tensor of latent vectors of shape\n",
        "\n",
        "    Args:\n",
        "      - model : trained model\n",
        "      - dataset: PyTorch dataset of images\n",
        "\n",
        "    Returns:\n",
        "      - latent_vectors - Torch tensor of dimension (len(dataset), latent_dim).\n",
        "    '''\n",
        "    latent_vectors = None\n",
        "    # ==== BEGIN SOLUTION CODE ====\n",
        "\n",
        "    # ==== END SOLUTION CODE ====\n",
        "    return latent_vectors"
      ],
      "metadata": {
        "id": "N4d3UPbHXNvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to generate the latent vectors of the images from the `mnist_train` dataset using your `model` and the `generate_latent_vectors` dataset."
      ],
      "metadata": {
        "id": "ZWPMyTjjwueQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_vectors = generate_latent_vectors(model, mnist_train)"
      ],
      "metadata": {
        "id": "gqG7afFMc0KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the `cosine_sim` function that computes the cosine similarity between each row of input tensors `a` and `b` and the 1-D tensor of indices with the of the `k` closest values.\n",
        "\n",
        "\n",
        "*Hint: You can use the [torch.nn.functional.cosine_similarity](https://pytorch.org/docs/stable/generated/torch.nn.functional.cosine_similarity.html#torch.nn.functional.cosine_similarity) and\n",
        "[torch.topk](https://pytorch.org/docs/stable/generated/torch.topk.html) functions. Make sure you use the appropriate parameters*  "
      ],
      "metadata": {
        "id": "37XT_cLIYVTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_sim(a, b, k=5):\n",
        "    # ==== BEGIN SOLUTION CODE ====\n",
        "\n",
        "    # ==== END SOLUTION CODE ===="
      ],
      "metadata": {
        "id": "UCUKPmZ6d1r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the `l2_pairwise_dist` function that computes the l2 distance between each row of input tensors `a` and `b` and returns the 1-D tensor of indices with the of the `k` closest values.\n",
        "\n",
        "*Hint: You can use the [torch.nn.functional.pairwise_distance](https://pytorch.org/docs/stable/generated/torch.nn.functional.pairwise_distance.html#torch.nn.functional.pairwise_distance) and\n",
        "[torch.topk](https://pytorch.org/docs/stable/generated/torch.topk.html) functions. Make sure you use the appropriate parameters*"
      ],
      "metadata": {
        "id": "j64XVqn7imro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def l2_pairwise_dist(a, b, k=5):\n",
        "    # ==== BEGIN SOLUTION CODE ====\n",
        "\n",
        "    # ==== END SOLUTION CODE ===="
      ],
      "metadata": {
        "id": "lCu5P2t9d3Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following function to find the top-k most similar images for a given image using a given 2-D array of latent vectors.\n",
        "\n",
        "The arguments are:\n",
        "  - `img`: The image to search similar images for.\n",
        "  - `model`: The trained model to use to generate latent vector of `img`.\n",
        "  - `latents`: The 2D tensor of latent vectors of the training dataset. Find the similar vectors to `img`s latent vector within this 2D tensor.\n",
        "  - `k`: The number of indices to return (default: 5)\n",
        "  - `distance_function`: The distance function to use to measure the similarity between latent vectors.  \n",
        "  \n",
        "\n",
        "Returns:\n",
        "    - The 1-D tensor of indices of the similar images to `img`\n",
        "\n",
        "\n",
        "Get the latent vector of `img` using your `model`s `encode` and then use the `distance_function` to get the `k`-nearest vectors."
      ],
      "metadata": {
        "id": "1X7NH7cwLM_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_top_k(img, model, latents, k = 5, distance_function=cosine_sim):\n",
        "    ind = None\n",
        "    # ==== BEGIN SOLUTION CODE ====\n",
        "\n",
        "    # ==== END SOLUTION CODE ====\n",
        "    return ind"
      ],
      "metadata": {
        "id": "Q1E1BdNwfbNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to define the top-k image visualization helper function."
      ],
      "metadata": {
        "id": "FnR1cK8huvdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_top_k_images(root_image, images):\n",
        "\n",
        "    num_images = len(images) + 1\n",
        "    sqrtimg = int(math.ceil(math.sqrt(28)))\n",
        "\n",
        "    fig = plt.figure(figsize=(num_images*2.5, num_images*5))\n",
        "    gs = gridspec.GridSpec(1, num_images)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "    images = [root_image] + images\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis(\"off\")\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect(\"equal\")\n",
        "        plt.imshow(img.reshape([28, 28]))\n",
        "        if i == 0:\n",
        "            ax.set_title(\"Search Image\")\n",
        "    return"
      ],
      "metadata": {
        "id": "rXfiWm3QoxVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to get the 5 most similar images to an image from the test set using a cosine similarity metric.\n",
        "\n",
        "If all the above cells are completed correctly, there should be no errors, and the found images should look visually similar."
      ],
      "metadata": {
        "id": "nF5Ttbiyu3B-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_img_ind = 19\n",
        "root_img = mnist_test[root_img_ind][0]\n",
        "_inds = find_top_k(root_img, model, training_vectors, k=5, distance_function= cosine_sim)\n",
        "images = []\n",
        "for i in _inds:\n",
        "    images.append(mnist_train[i][0])\n",
        "show_top_k_images(root_img, images)"
      ],
      "metadata": {
        "id": "NBd2UG6dnNgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to get the 5 most similar images to an image from the test set using a cosine similarity metric using the MAE.\n",
        "\n",
        "If all the above cells are completed correctly, there should be no errors, and the found images should look visually similar."
      ],
      "metadata": {
        "id": "kCXf5Ry7bWQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_img_ind = 19\n",
        "root_img = mnist_test[root_img_ind][0]\n",
        "_inds = find_top_k(root_img, mae_model, training_vectors, k=5, distance_function= cosine_sim)\n",
        "images = []\n",
        "for i in _inds:\n",
        "    images.append(mnist_train[i][0])\n",
        "show_top_k_images(root_img, images)"
      ],
      "metadata": {
        "id": "Qg3T3NmDbU4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to get the 5 most similar images to an image from the test set using a $\\mathcal{l}_2$ distance.\n",
        "\n",
        "\n",
        "If all the above cells are completed correctly, there should be no errors, and the found images should look visually similar."
      ],
      "metadata": {
        "id": "duLY_18Usuts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_img_ind = 19\n",
        "root_img = mnist_test[root_img_ind][0]\n",
        "_inds = find_top_k(root_img, model, training_vectors, k=5, distance_function=l2_pairwise_dist)\n",
        "images = []\n",
        "for i in _inds:\n",
        "    images.append(mnist_train[i][0])\n",
        "show_top_k_images(root_img, images)"
      ],
      "metadata": {
        "id": "fp5XZXdUnTVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to get the 5 most similar images to an image from the test set using a $\\mathcal{l}_2$ distance using the MAE.\n",
        "\n",
        "\n",
        "If all the above cells are completed correctly, there should be no errors, and the found images should look visually similar."
      ],
      "metadata": {
        "id": "nMM-KmkmbeJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_img_ind = 19\n",
        "root_img = mnist_test[root_img_ind][0]\n",
        "_inds = find_top_k(root_img, mae_model, training_vectors, k=5, distance_function=l2_pairwise_dist)\n",
        "images = []\n",
        "for i in _inds:\n",
        "    images.append(mnist_train[i][0])\n",
        "show_top_k_images(root_img, images)"
      ],
      "metadata": {
        "id": "HGNVLa6mbeRO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}